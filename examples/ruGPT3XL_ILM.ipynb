{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-XkQgf-ufgE"
      },
      "source": [
        "## Install lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ww7j9jv9vz4"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "rm -rf /usr/local/cuda\n",
        "ln -s /usr/local/cuda-10.1 /usr/local/cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlBd2_Rx-AF6",
        "outputId": "9bcb917b-47e3-4cd4-bd25-76a2c097f19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNYm0tJkFhQ-",
        "outputId": "6e8f725d-3e8b-42b6-d7b4-6b73c35d5382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  File: /usr/local/cuda -> /usr/local/cuda-10.1\n",
            "  Size: 20        \tBlocks: 0          IO Block: 4096   symbolic link\n",
            "Device: 34h/52d\tInode: 3028158     Links: 1\n",
            "Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)\n",
            "Access: 2021-11-22 11:48:01.494879953 +0000\n",
            "Modify: 2021-11-22 11:48:01.447879968 +0000\n",
            "Change: 2021-11-22 11:48:01.447879968 +0000\n",
            " Birth: -\n"
          ]
        }
      ],
      "source": [
        "!stat /usr/local/cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_s1SIgOXFqu",
        "outputId": "6e1b91c8-6ac1-43c2-bb22-75c85465f038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping triton as it is not installed.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEyNr3ECXdWy"
      },
      "outputs": [],
      "source": [
        "!pip uninstall torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gH2kLmcXmL3e"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "export LD_LIBRARY_PATH=/usr/lib/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRkBHiuOFYB-",
        "outputId": "18ddbde9-eb54-4370-9995-757a32e16eb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "clang-9 is already the newest version (1:9-2~ubuntu18.04.2).\n",
            "llvm-9 is already the newest version (1:9-2~ubuntu18.04.2).\n",
            "llvm-9-dev is already the newest version (1:9-2~ubuntu18.04.2).\n",
            "llvm-9-tools is already the newest version (1:9-2~ubuntu18.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install clang-9 llvm-9 llvm-9-dev llvm-9-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhaVMe06-582"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tUl_ovYQz0x",
        "outputId": "f0b6fd1f-74ae-49a9-a8b9-a941cebc602d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbA0nb2-Q1bF"
      },
      "outputs": [],
      "source": [
        "!sh setup.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz8j2jFOEjL5"
      },
      "outputs": [],
      "source": [
        "!pip install triton==0.2.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2Ycg7S8SFOBr"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y typing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wol0NpsxFRRz"
      },
      "outputs": [],
      "source": [
        "!pip install cpufeature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEyrQ-spCdhR"
      },
      "outputs": [],
      "source": [
        "!DS_BUILD_CPU_ADAM=1 DS_BUILD_SPARSE_ATTN=1 pip install deepspeed==0.3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "---7k9osCliv",
        "outputId": "de3f13c7-a617-4672-e7fd-f32c33346357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "cpu_adam ............... \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "sparse_attn ............ \u001b[92m[YES]\u001b[0m ...... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "utils .................. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/usr/local/lib/python3.7/dist-packages/torch']\n",
            "torch version .................... 1.6.0+cu101\n",
            "torch cuda version ............... 10.1\n",
            "nvcc version ..................... 10.1\n",
            "deepspeed install path ........... ['/usr/local/lib/python3.7/dist-packages/deepspeed']\n",
            "deepspeed info ................... 0.3.7, unknown, unknown\n",
            "deepspeed wheel compiled w. ...... torch 1.6, cuda 10.1\n"
          ]
        }
      ],
      "source": [
        "!ds_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DqPIkEYjCmLH"
      },
      "outputs": [],
      "source": [
        "import deepspeed.ops.sparse_attention.sparse_attn_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gw4lJHfX4QnB"
      },
      "outputs": [],
      "source": [
        "!rm -rf ru-gpts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t43yH5k1jtZZ",
        "outputId": "2727814a-bb77-4690-921b-a6ec7be409f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'ru-gpts'...\n",
            "remote: Enumerating objects: 673, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 673 (delta 103), reused 135 (delta 80), pack-reused 505\u001b[K\n",
            "Receiving objects: 100% (673/673), 402.50 KiB | 3.73 MiB/s, done.\n",
            "Resolving deltas: 100% (403/403), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lauberto/rugpt3xl_ilm.git\n",
        " # TODO: add path to requirements.txt and install requirements (make sure to use the requirements necessary both for ILM and RUGP3XL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2XiJvm_tQgL"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==3.5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1RCujWwJUwm-"
      },
      "outputs": [],
      "source": [
        "!cp rugpt3xl_ilm/src_utils/trainer_pt_utils.py /usr/local/lib/python3.7/dist-packages/transformers/trainer_pt_utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TbybJfIpBVa"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU8lvJHAjpPQ"
      },
      "source": [
        "### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EnTy1SEajpPV"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z-DSEz0ljpPV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"ru-gpts/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_9GABoxNVpH4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"USE_DEEPSPEED\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ILM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive/RUGPT3XL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: upload data to gdrive\n",
        "# TODO: use the right path for the script below\n",
        "!! python train_ilm.py \\\n",
        "\texperiment \\\n",
        "  sberbank_small \\\n",
        "\t./data/Economics/ \\\n",
        "\t--seed 0 \\\n",
        "\t--train_examples_tag train \\\n",
        "  --data_loader_num_workers 8 \\\n",
        "  --eval_examples_tag valid \\\n",
        "  --eval_max_num_examples 512 \\\n",
        "  --tokenizer_name CUSTOM \\\n",
        "  --tokenizer_custom_vocab_fp rus_gpt2/vocab.json \\\n",
        "  --model_name sberbank-ai/rugpt3small_based_on_gpt2 2>&1 | tee sberbank_CAT_TrainerLog.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw4Iv-Dl3q05"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ruGPT3XL_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
